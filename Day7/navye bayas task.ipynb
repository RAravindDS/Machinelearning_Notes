{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/aravi/Downloads/ML learning notes/Day7/continuos/credit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('default').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows =1,ncols =4 ,figsize=(20,5))\n",
    "\n",
    "ax = sns.distplot(data['income'],ax = axes[0],bins = 50 )\n",
    "ax.set_title('income')\n",
    "ax.legend()\n",
    "ax = sns.distplot(data['age'],ax= axes[1],bins = 50)\n",
    "ax.set_title('age')\n",
    "ax.legend()\n",
    "ax = sns.distplot(data['loan'],ax = axes[2],bins = 50)\n",
    "ax.set_title('loan')\n",
    "ax.legend()\n",
    "ax = sns.distplot(data['LTI'],ax = axes[3],bins = 50)\n",
    "ax.set_title('lti')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['default'].plot(kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['income','age','loan']]\n",
    "y = data['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,t_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,r_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,r_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,r_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding which is perfect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gausssian(y_test,y_pred):\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descison():\n",
    "    print(accuracy_score(y_test,t_pred))\n",
    "    print(confusion_matrix(y_test,t_pred))\n",
    "    print(classification_report(y_test,t_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random():\n",
    "    print(accuracy_score(y_test,r_pred))\n",
    "    print(confusion_matrix(y_test,r_pred))\n",
    "    print(classification_report(y_test,r_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic():\n",
    "    print(accuracy_score(y_test,lr_pred))\n",
    "    print(confusion_matrix(y_test,lr_pred))\n",
    "    print(classification_report(y_test,lr_pred))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    if model_name == \"tree\":\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "    else:\n",
    "        model = model_name()\n",
    "        \n",
    "    model = model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n",
      "[[547  15]\n",
      " [ 45  53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       562\n",
      "           1       0.78      0.54      0.64        98\n",
      "\n",
      "    accuracy                           0.91       660\n",
      "   macro avg       0.85      0.76      0.79       660\n",
      "weighted avg       0.90      0.91      0.90       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_model(LogisticRegression,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833333333333333\n",
      "[[560   2]\n",
      " [  9  89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       562\n",
      "           1       0.98      0.91      0.94        98\n",
      "\n",
      "    accuracy                           0.98       660\n",
      "   macro avg       0.98      0.95      0.97       660\n",
      "weighted avg       0.98      0.98      0.98       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_model(\"tree\",X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9848484848484849\n",
      "[[562   0]\n",
      " [ 10  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       562\n",
      "           1       1.00      0.90      0.95        98\n",
      "\n",
      "    accuracy                           0.98       660\n",
      "   macro avg       0.99      0.95      0.97       660\n",
      "weighted avg       0.99      0.98      0.98       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_model(RandomForestClassifier,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9257575757575758\n",
      "[[553   9]\n",
      " [ 40  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       562\n",
      "           1       0.87      0.59      0.70        98\n",
      "\n",
      "    accuracy                           0.93       660\n",
      "   macro avg       0.90      0.79      0.83       660\n",
      "weighted avg       0.92      0.93      0.92       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_model(GaussianNB,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(LogisticRegression,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descision tree is a good model !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "questions bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doubt ; where we have to use the confusion and mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding ? in mutlinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spam vs ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 135-136: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 135-136: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-d06685de8dff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/aravi/Downloads/ML learning notes/Day7/Multinomial/spam.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 135-136: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/aravi/Downloads/ML learning notes/Day7/Multinomial/spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'v1':'class_label','v2':'message'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = cols ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>message</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_label                                            message Unnamed: 2  \\\n",
       "0         ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1         ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3         ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 4'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>message</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_label                                            message Unnamed: 2  \\\n",
       "0         ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1         ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3         ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_label       0\n",
       "message           0\n",
       "Unnamed: 2     5522\n",
       "Unnamed: 3     5560\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_label  message                                                                                                                                          Unnamed: 2                                                                    Unnamed: 3                                \n",
       "spam         Your free ringtone is waiting to be collected. Simply text the password \\MIX\\\" to 85069 to verify. Get Usher and Britney. FML                     PO Box 5249                                                                   MK17 92H. 450Ppw 16\"                         2\n",
       "ham          Edison has rightly said, \\A fool can ask more questions than a wise man can answer\\\" Now you know why all of us are speechless during ViVa.. GM  GN                                                                            GE                                            2\n",
       "             \\Wen u miss someone                                                                                                                               the person is definitely special for u..... But if the person is so special   why to miss them                             1\n",
       "             \\SHIT BABE.. THASA BIT MESSED UP.YEH                                                                                                              SHE SHUDVETOLD U. DID URGRAN KNOW?NEWAY                                       ILLSPEAK 2 U2MORO WEN IM NOT ASLEEP...\\\"\"    1\n",
       "             \\HI BABE UAWAKE?FEELLIKW SHIT.JUSTFOUND OUT VIA ALETTER THATMUM GOTMARRIED 4thNOV.BEHIND OURBACKS åÐ FUCKINNICE!SELFISH                          DEVIOUSBITCH.ANYWAY                                                           IåÕL CALL U\\\"\"                                1\n",
       "             \\HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DEAD 2 DA WRLD. BEEN SLEEPING ON DA SOFA ALL DAY                                                      HAD A COOL NYTHO                                                              TX 4 FONIN HON                               1\n",
       "             \\CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER IF URGOIN OUTL8R                                                                                  JUST REALLYNEED 2DOCD.PLEASE DONTPLEASE DONTIGNORE MYCALLS                    U NO THECD ISV.IMPORTANT TOME 4 2MORO\\\"\"      1\n",
       "             When I was born, GOD said, \\Oh No! Another IDIOT\\\". When you were born                                                                            GOD said                                                                      \\\"OH No! COMPETITION\\\". Who knew             1\n",
       "             Two fundamentals of cool life: \\Walk                                                                                                              like you are the KING\\\"...! OR \\\"Walk like you Dont care                     whoever is the KING\\\"!... Gud nyt\"            1\n",
       "             I just lov this line: \\Hurt me with the truth                                                                                                     I don't mind                                                                 i wil tolerat.bcs ur my someone..... But      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>message</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class_label                 message  \\\n",
       "count         5572                    5572   \n",
       "unique           2                    5169   \n",
       "top            ham  Sorry, I'll call later   \n",
       "freq          4825                      30   \n",
       "\n",
       "                                               Unnamed: 2 Unnamed: 3  \n",
       "count                                                  50         12  \n",
       "unique                                                 43         10  \n",
       "top      bt not his girlfrnd... G o o d n i g h t . . .@\"         GE  \n",
       "freq                                                    3          2  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_label'] = df['class_label'].apply(lambda X: 1 if X == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['class_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "lst = X_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "input = lst,\n",
    "lowercase = True,\n",
    "stop_words = 'english'\n",
    ")\n",
    "features_train_transformed = vectorizer.fit_transform(lst)\n",
    "\n",
    "features_test_transformed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000pes',\n",
       " '008704050406',\n",
       " '0089',\n",
       " '0121',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '0125698789',\n",
       " '02',\n",
       " '0207',\n",
       " '02072069400',\n",
       " '02073162414',\n",
       " '02085076972',\n",
       " '021',\n",
       " '03',\n",
       " '04',\n",
       " '0430',\n",
       " '05',\n",
       " '0578',\n",
       " '06',\n",
       " '07008009200',\n",
       " '07099833605',\n",
       " '07123456789',\n",
       " '0721072',\n",
       " '07734396839',\n",
       " '07742676969',\n",
       " '07753741225',\n",
       " '0776xxxxxxx',\n",
       " '07781482378',\n",
       " '07786200117',\n",
       " '077xxx',\n",
       " '078',\n",
       " '07808247860',\n",
       " '07808726822',\n",
       " '07821230901',\n",
       " '07880867867',\n",
       " '0789xxxxxxx',\n",
       " '07946746291',\n",
       " '0796xxxxxx',\n",
       " '07973788240',\n",
       " '07xxxxxxxxx',\n",
       " '08',\n",
       " '0800',\n",
       " '08000407165',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '08000938767',\n",
       " '08001950382',\n",
       " '08002888812',\n",
       " '08002986030',\n",
       " '08002986906',\n",
       " '08006344447',\n",
       " '0808',\n",
       " '08081263000',\n",
       " '08081560665',\n",
       " '0825',\n",
       " '0844',\n",
       " '08448350055',\n",
       " '08448714184',\n",
       " '0845',\n",
       " '08452810071',\n",
       " '08452810073',\n",
       " '08452810075over18',\n",
       " '0870',\n",
       " '08700435505150p',\n",
       " '08700469649',\n",
       " '08700621170150p',\n",
       " '08701213186',\n",
       " '08701237397',\n",
       " '08701417012',\n",
       " '08701417012150p',\n",
       " '087016248',\n",
       " '08701752560',\n",
       " '0870241182716',\n",
       " '08702840625',\n",
       " '08704050406',\n",
       " '08704439680',\n",
       " '08704439680ts',\n",
       " '08706091795',\n",
       " '08707509020',\n",
       " '08707808226',\n",
       " '08708034412',\n",
       " '08708800282',\n",
       " '08709222922',\n",
       " '0871',\n",
       " '087104711148',\n",
       " '08712101358',\n",
       " '08712103738',\n",
       " '0871212025016',\n",
       " '08712300220',\n",
       " '087123002209am',\n",
       " '08712317606',\n",
       " '08712400602450p',\n",
       " '08712400603',\n",
       " '08712402050',\n",
       " '08712402578',\n",
       " '08712402779',\n",
       " '08712402902',\n",
       " '08712404000',\n",
       " '08712405020',\n",
       " '08712405022',\n",
       " '08712460324',\n",
       " '08712466669',\n",
       " '0871277810710p',\n",
       " '0871277810910p',\n",
       " '08714712379',\n",
       " '08714712388',\n",
       " '08714714011',\n",
       " '08715203649',\n",
       " '08715203677',\n",
       " '08715203694',\n",
       " '08715205273',\n",
       " '08715500022',\n",
       " '08715705022',\n",
       " '08717111821',\n",
       " '08717168528',\n",
       " '08717205546',\n",
       " '0871750',\n",
       " '08717507382',\n",
       " '08717890890å',\n",
       " '08717895698',\n",
       " '08717898035',\n",
       " '08718711108',\n",
       " '08718720201',\n",
       " '08718725756',\n",
       " '08718726270',\n",
       " '087187262701',\n",
       " '08718726978',\n",
       " '087187272008',\n",
       " '08718727868',\n",
       " '08718730666',\n",
       " '08718738001',\n",
       " '08718738002',\n",
       " '08719180248',\n",
       " '08719181259',\n",
       " '08719181503',\n",
       " '08719839835',\n",
       " '08719899229',\n",
       " '09',\n",
       " '09041940223',\n",
       " '09050000301',\n",
       " '09050000332',\n",
       " '09050001295',\n",
       " '09050001808',\n",
       " '09050002311',\n",
       " '09050003091',\n",
       " '09050090044',\n",
       " '09050280520',\n",
       " '09053750005',\n",
       " '09056242159',\n",
       " '09057039994',\n",
       " '09058091854',\n",
       " '09058094454',\n",
       " '09058094455',\n",
       " '09058094583',\n",
       " '09058094594',\n",
       " '09058094597',\n",
       " '09058094599',\n",
       " '09058095201',\n",
       " '09058097189',\n",
       " '09058097218',\n",
       " '09058098002',\n",
       " '09058099801',\n",
       " '09061104276',\n",
       " '09061104283',\n",
       " '09061209465',\n",
       " '09061213237',\n",
       " '09061221061',\n",
       " '09061221066',\n",
       " '09061701444',\n",
       " '09061701461',\n",
       " '09061701851',\n",
       " '09061701939',\n",
       " '09061702893',\n",
       " '09061743386',\n",
       " '09061743806',\n",
       " '09061743810',\n",
       " '09061744553',\n",
       " '09061790121',\n",
       " '09061790126',\n",
       " '09063440451',\n",
       " '09063442151',\n",
       " '09063458130',\n",
       " '09064011000',\n",
       " '09064012103',\n",
       " '09064012160',\n",
       " '09064015307',\n",
       " '09064017295',\n",
       " '09064017305',\n",
       " '09064018838',\n",
       " '09064019014',\n",
       " '09064019788',\n",
       " '09065069154',\n",
       " '09065171142',\n",
       " '09065174042',\n",
       " '09065394514',\n",
       " '09065989182',\n",
       " '09066358152',\n",
       " '09066358361',\n",
       " '09066361921',\n",
       " '09066362206',\n",
       " '09066362220',\n",
       " '09066362231',\n",
       " '09066364311',\n",
       " '09066364589',\n",
       " '09066368327',\n",
       " '09066368470',\n",
       " '09066368753',\n",
       " '09066380611',\n",
       " '09066382422',\n",
       " '09066612661',\n",
       " '09066660100',\n",
       " '09071512432',\n",
       " '09071517866',\n",
       " '09077818151',\n",
       " '09094100151',\n",
       " '09094646631',\n",
       " '09094646899',\n",
       " '09096102316',\n",
       " '09099726395',\n",
       " '09099726553',\n",
       " '09111032124',\n",
       " '09701213186',\n",
       " '0a',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000call',\n",
       " '1000s',\n",
       " '100p',\n",
       " '100percent',\n",
       " '100txt',\n",
       " '1030',\n",
       " '10am',\n",
       " '10k',\n",
       " '10p',\n",
       " '10ppm',\n",
       " '11',\n",
       " '113',\n",
       " '114',\n",
       " '116',\n",
       " '118p',\n",
       " '11mths',\n",
       " '11pm',\n",
       " '12',\n",
       " '121',\n",
       " '1225',\n",
       " '123',\n",
       " '125',\n",
       " '125gift',\n",
       " '128',\n",
       " '12hours',\n",
       " '12hrs',\n",
       " '12mths',\n",
       " '13',\n",
       " '130',\n",
       " '1327',\n",
       " '14',\n",
       " '1405',\n",
       " '140ppm',\n",
       " '145',\n",
       " '1450',\n",
       " '146tf150p',\n",
       " '14thmarch',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150p',\n",
       " '150p16',\n",
       " '150pm',\n",
       " '150ppermesssubscription',\n",
       " '150ppm',\n",
       " '150ppmpobox10183bhamb64xe',\n",
       " '150pw',\n",
       " '151',\n",
       " '153',\n",
       " '15541',\n",
       " '15pm',\n",
       " '16',\n",
       " '1680',\n",
       " '169',\n",
       " '177',\n",
       " '18',\n",
       " '1843',\n",
       " '18p',\n",
       " '18yrs',\n",
       " '195',\n",
       " '1956669',\n",
       " '1apple',\n",
       " '1b6a5ecef91ff9',\n",
       " '1cup',\n",
       " '1er',\n",
       " '1hr',\n",
       " '1lemon',\n",
       " '1mega',\n",
       " '1million',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1st4terms',\n",
       " '1stchoice',\n",
       " '1stone',\n",
       " '1thing',\n",
       " '1tulsi',\n",
       " '1win150ppmx3',\n",
       " '1winaweek',\n",
       " '1winawk',\n",
       " '1x150p',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2007',\n",
       " '2025050',\n",
       " '20m12aq',\n",
       " '20p',\n",
       " '21',\n",
       " '21870000',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '220cm2',\n",
       " '2309',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24m',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '250k',\n",
       " '255',\n",
       " '25p',\n",
       " '26',\n",
       " '2667',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '2814032',\n",
       " '28days',\n",
       " '28th',\n",
       " '29',\n",
       " '2b',\n",
       " '2bold',\n",
       " '2c',\n",
       " '2day',\n",
       " '2end',\n",
       " '2exit',\n",
       " '2find',\n",
       " '2getha',\n",
       " '2geva',\n",
       " '2go',\n",
       " '2hrs',\n",
       " '2kbsubject',\n",
       " '2lands',\n",
       " '2marrow',\n",
       " '2moro',\n",
       " '2morow',\n",
       " '2morro',\n",
       " '2morrow',\n",
       " '2morrowxxxx',\n",
       " '2mrw',\n",
       " '2nd',\n",
       " '2nite',\n",
       " '2optout',\n",
       " '2p',\n",
       " '2price',\n",
       " '2px',\n",
       " '2rcv',\n",
       " '2stop',\n",
       " '2stoptx',\n",
       " '2stoptxt',\n",
       " '2u',\n",
       " '2u2',\n",
       " '2waxsto',\n",
       " '2wks',\n",
       " '2wt',\n",
       " '2years',\n",
       " '2yr',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300603',\n",
       " '300603t',\n",
       " '3030',\n",
       " '30ish',\n",
       " '30pm',\n",
       " '30pp',\n",
       " '30s',\n",
       " '30th',\n",
       " '31',\n",
       " '3100',\n",
       " '310303',\n",
       " '31p',\n",
       " '32',\n",
       " '326',\n",
       " '33',\n",
       " '350',\n",
       " '3510i',\n",
       " '3650',\n",
       " '36504',\n",
       " '3680',\n",
       " '373',\n",
       " '3750',\n",
       " '37819',\n",
       " '382',\n",
       " '391784',\n",
       " '3aj',\n",
       " '3d',\n",
       " '3g',\n",
       " '3gbp',\n",
       " '3hrs',\n",
       " '3lp',\n",
       " '3miles',\n",
       " '3mins',\n",
       " '3mobile',\n",
       " '3optical',\n",
       " '3pound',\n",
       " '3qxj9',\n",
       " '3rd',\n",
       " '3ss',\n",
       " '3uz',\n",
       " '3wks',\n",
       " '3xx',\n",
       " '3xå',\n",
       " '40',\n",
       " '400',\n",
       " '400mins',\n",
       " '402',\n",
       " '40411',\n",
       " '40533',\n",
       " '40gb',\n",
       " '4217',\n",
       " '42478',\n",
       " '430',\n",
       " '434',\n",
       " '44',\n",
       " '440',\n",
       " '4403ldnw1a7rw18',\n",
       " '447801259231',\n",
       " '448712404000',\n",
       " '449050000301',\n",
       " '45',\n",
       " '450',\n",
       " '450p',\n",
       " '45239',\n",
       " '45pm',\n",
       " '4742',\n",
       " '48',\n",
       " '4882',\n",
       " '48922',\n",
       " '49557',\n",
       " '4a',\n",
       " '4d',\n",
       " '4eva',\n",
       " '4fil',\n",
       " '4get',\n",
       " '4goten',\n",
       " '4info',\n",
       " '4jx',\n",
       " '4mths',\n",
       " '4qf2',\n",
       " '4t',\n",
       " '4th',\n",
       " '4the',\n",
       " '4thnov',\n",
       " '4txt',\n",
       " '4u',\n",
       " '4utxt',\n",
       " '4wrd',\n",
       " '4years',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '505060',\n",
       " '50award',\n",
       " '50ea',\n",
       " '50gbp',\n",
       " '50p',\n",
       " '50perweeksub',\n",
       " '50perwksub',\n",
       " '50pm',\n",
       " '50pmmorefrommobile2bremoved',\n",
       " '50ppm',\n",
       " '50s',\n",
       " '515',\n",
       " '526',\n",
       " '530',\n",
       " '54',\n",
       " '542',\n",
       " '5digital',\n",
       " '5free',\n",
       " '5k',\n",
       " '5min',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5th',\n",
       " '5wb',\n",
       " '5we',\n",
       " '5wkg',\n",
       " '5wq',\n",
       " '5years',\n",
       " '600',\n",
       " '6031',\n",
       " '60p',\n",
       " '61',\n",
       " '61200',\n",
       " '61610',\n",
       " '62220cncl',\n",
       " '62468',\n",
       " '62735',\n",
       " '630',\n",
       " '645',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '6669',\n",
       " '674',\n",
       " '67441233',\n",
       " '68866',\n",
       " '69200',\n",
       " '69669',\n",
       " '69696',\n",
       " '69855',\n",
       " '69866',\n",
       " '69888',\n",
       " '69888nyt',\n",
       " '69911',\n",
       " '69969',\n",
       " '6days',\n",
       " '6hl',\n",
       " '6hrs',\n",
       " '6ish',\n",
       " '6missed',\n",
       " '6months',\n",
       " '6ph',\n",
       " '6pm',\n",
       " '6th',\n",
       " '6wu',\n",
       " '6zf',\n",
       " '71',\n",
       " '7250',\n",
       " '7250i',\n",
       " '731',\n",
       " '74355',\n",
       " '75',\n",
       " '750',\n",
       " '75max',\n",
       " '762',\n",
       " '77',\n",
       " '7732584351',\n",
       " '786',\n",
       " '7876150ppm',\n",
       " '79',\n",
       " '7ish',\n",
       " '7oz',\n",
       " '7pm',\n",
       " '7th',\n",
       " '7ws',\n",
       " '800',\n",
       " '8000930705',\n",
       " '80062',\n",
       " '8007',\n",
       " '80082',\n",
       " '80086',\n",
       " '80122300p',\n",
       " '80160',\n",
       " '80182',\n",
       " '8027',\n",
       " '80488',\n",
       " '80608',\n",
       " '8077',\n",
       " '80878',\n",
       " '81010',\n",
       " '81151',\n",
       " '81303',\n",
       " '82050',\n",
       " '82242',\n",
       " '82277',\n",
       " '82324',\n",
       " '83021',\n",
       " '83039',\n",
       " '83049',\n",
       " '83110',\n",
       " '83118',\n",
       " '83222',\n",
       " '83332',\n",
       " '83355',\n",
       " '83370',\n",
       " '83383',\n",
       " '83435',\n",
       " '83600',\n",
       " '83738',\n",
       " '84025',\n",
       " '84128',\n",
       " '84199',\n",
       " '85',\n",
       " '850',\n",
       " '85023',\n",
       " '8552',\n",
       " '85555',\n",
       " '86021',\n",
       " '861',\n",
       " '86688',\n",
       " '86888',\n",
       " '87021',\n",
       " '87066',\n",
       " '87070',\n",
       " '87077',\n",
       " '87121',\n",
       " '87131',\n",
       " '8714714',\n",
       " '872',\n",
       " '87239',\n",
       " '87575',\n",
       " '8800',\n",
       " '88039',\n",
       " '88066',\n",
       " '88088',\n",
       " '88222',\n",
       " '88600',\n",
       " '88800',\n",
       " '8883',\n",
       " '88888',\n",
       " '89034',\n",
       " '89080',\n",
       " '89123',\n",
       " '89545',\n",
       " '89555',\n",
       " '89693',\n",
       " '89938',\n",
       " '8am',\n",
       " '8lb',\n",
       " '8p',\n",
       " '8pm',\n",
       " '8th',\n",
       " '900',\n",
       " '9061100010',\n",
       " '910',\n",
       " '9153',\n",
       " '9280114',\n",
       " '930',\n",
       " '946',\n",
       " '95',\n",
       " '9755',\n",
       " '9758',\n",
       " '97n7qp',\n",
       " '98321561',\n",
       " '99',\n",
       " '9996',\n",
       " '9ae',\n",
       " '9am',\n",
       " '9ja',\n",
       " '9pm',\n",
       " '9t',\n",
       " '9yt',\n",
       " '____',\n",
       " 'a21',\n",
       " 'a30',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aaniye',\n",
       " 'aaooooright',\n",
       " 'aathi',\n",
       " 'ab',\n",
       " 'abbey',\n",
       " 'abdomen',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'able',\n",
       " 'abnormally',\n",
       " 'aboutas',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absolutly',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'ac',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accenture',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accidant',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodation',\n",
       " 'accommodationvouchers',\n",
       " 'accomodate',\n",
       " 'accomodations',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulation',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'acl03530150pm',\n",
       " 'acnt',\n",
       " 'aco',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activ8',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addie',\n",
       " 'adding',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'adewale',\n",
       " 'admin',\n",
       " 'administrator',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'adore',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adsense',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'adventure',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisors',\n",
       " 'aeronautics',\n",
       " 'aeroplane',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affections',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'age16',\n",
       " 'age23',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'agidhane',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahold',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'airtel',\n",
       " 'aiya',\n",
       " 'aiyah',\n",
       " 'aiyar',\n",
       " 'aiyo',\n",
       " 'ajith',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akon',\n",
       " 'al',\n",
       " 'alaikkum',\n",
       " 'alaipayuthe',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'aldrine',\n",
       " 'alert',\n",
       " 'alertfrom',\n",
       " 'alerts',\n",
       " 'aletter',\n",
       " 'alex',\n",
       " 'alfie',\n",
       " 'algarve',\n",
       " 'algebra',\n",
       " 'alian',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allalo',\n",
       " 'allday',\n",
       " 'alle',\n",
       " 'allo',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'alot',\n",
       " 'alright',\n",
       " 'alrite',\n",
       " 'alter',\n",
       " 'alternative',\n",
       " 'aluable',\n",
       " 'alwa',\n",
       " 'alwys',\n",
       " 'amanda',\n",
       " 'amazing',\n",
       " 'ambitious',\n",
       " 'ambrith',\n",
       " 'american',\n",
       " 'amigos',\n",
       " 'ammo',\n",
       " 'amore',\n",
       " 'amp',\n",
       " 'amplikater',\n",
       " 'ams',\n",
       " 'amt',\n",
       " 'amused',\n",
       " 'amy',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'analysis',\n",
       " 'anand',\n",
       " 'anderson',\n",
       " 'andre',\n",
       " 'andres',\n",
       " 'andrews',\n",
       " 'andros',\n",
       " 'angry',\n",
       " 'animation',\n",
       " 'anjie',\n",
       " 'anjola',\n",
       " 'anna',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'announcement',\n",
       " 'annoying',\n",
       " 'anot',\n",
       " 'ans',\n",
       " 'ansr',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answerin',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'answr',\n",
       " 'antelope',\n",
       " 'antibiotic',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyones',\n",
       " 'anyplaces',\n",
       " 'anythiing',\n",
       " 'anythin',\n",
       " 'anythingtomorrow',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'aom',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apeshit',\n",
       " 'apo',\n",
       " 'apologise',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appendix',\n",
       " 'applausestore',\n",
       " 'applebees',\n",
       " 'apples',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'applyed',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approx',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'appy',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aptitude',\n",
       " 'aquarius',\n",
       " 'ar',\n",
       " 'arabian',\n",
       " 'arcade',\n",
       " 'archive',\n",
       " 'ard',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'arestaurant',\n",
       " 'aretaking',\n",
       " 'areyouunique',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'aries',\n",
       " 'arise',\n",
       " 'arises',\n",
       " 'arithmetic',\n",
       " 'arm',\n",
       " 'armand',\n",
       " 'armenia',\n",
       " 'arms',\n",
       " 'arng',\n",
       " 'arngd',\n",
       " 'arnt',\n",
       " 'aroundn',\n",
       " 'arrange',\n",
       " 'arranging',\n",
       " 'arrested',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrow',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'arul',\n",
       " 'arun',\n",
       " 'asap',\n",
       " 'asda',\n",
       " 'ashes',\n",
       " 'ashley',\n",
       " 'ashwini',\n",
       " 'asjesus',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'asked',\n",
       " 'askin',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'assessment',\n",
       " 'assistance',\n",
       " 'associate',\n",
       " 'asssssholeeee',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'asthere',\n",
       " 'asthma',\n",
       " 'astronomer',\n",
       " 'asusual',\n",
       " 'ate',\n",
       " 'athletic',\n",
       " 'athome',\n",
       " 'atlanta',\n",
       " 'atlast',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atrocious',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'atten',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attitude',\n",
       " 'attractive',\n",
       " 'attracts',\n",
       " 'attributed',\n",
       " 'atural',\n",
       " 'auction',\n",
       " 'audition',\n",
       " 'audrey',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auntie',\n",
       " ...]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_labels = classifier.predict(features_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9641148325358851\n",
      "###################################\n",
      "[[1434    0]\n",
      " [  60  178]]\n",
      "###################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1434\n",
      "           1       1.00      0.75      0.86       238\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.98      0.87      0.92      1672\n",
      "weighted avg       0.97      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(accuracy_score(y_test,ypred_labels))\n",
    "    print('###################################')\n",
    "    print(confusion_matrix(y_test,ypred_labels))\n",
    "    print('###################################')\n",
    "    print(classification_report(y_test,ypred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descision treee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(features_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_pred = tree.predict(features_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605263157894737\n",
      "###################################\n",
      "[[1410   24]\n",
      " [  42  196]]\n",
      "###################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1434\n",
      "           1       0.89      0.82      0.86       238\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.93      0.90      0.92      1672\n",
      "weighted avg       0.96      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,tt_pred))\n",
    "print('###################################')\n",
    "print(confusion_matrix(y_test,tt_pred))\n",
    "print('###################################')\n",
    "print(classification_report(y_test,tt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc2.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2_pred = rfc2.predict(features_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694976076555024\n",
      "###################################\n",
      "[[1434    0]\n",
      " [  51  187]]\n",
      "###################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1434\n",
      "           1       1.00      0.79      0.88       238\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.98      0.89      0.93      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,rfc2_pred))\n",
    "print('###################################')\n",
    "print(confusion_matrix(y_test,rfc2_pred))\n",
    "print('###################################')\n",
    "print(classification_report(y_test,rfc2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2.fit(features_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_pred = lr2.predict(features_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9527511961722488\n",
      "###################################\n",
      "[[1431    3]\n",
      " [  76  162]]\n",
      "###################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1434\n",
      "           1       0.98      0.68      0.80       238\n",
      "\n",
      "    accuracy                           0.95      1672\n",
      "   macro avg       0.97      0.84      0.89      1672\n",
      "weighted avg       0.95      0.95      0.95      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,lr2_pred))\n",
    "print('###################################')\n",
    "print(confusion_matrix(y_test,lr2_pred))\n",
    "print('###################################')\n",
    "print(classification_report(y_test,lr2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# descision tree is the good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for both loan and spam model descison tree is performing well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
